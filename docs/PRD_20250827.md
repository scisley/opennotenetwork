# Product Requirements Document (PRD)

## Project Summary

This project develops an AI-powered system that generates and submits climate-related Community Notes on X.com. The system ingests note requests, classifies posts for climate relevance, and produces both a detailed fact check and a concise 280-character note with a link back to the full explanation. Admins can review, edit, and approve notes before submission, ensuring that the published content is accurate, neutral, and sourced from credible scientific references. The primary goal is to maximize the number of accepted notes while building a framework that could be adapted for other domains.

Beyond climate change, the system is designed to be modular and reusable, with components for ingestion, classification, note generation, and review. A minimal public site will host submitted and accepted notes, providing transparency and enabling broader access to fact checks. By combining automation with human oversight, the project aims to demonstrate a scalable approach to combating misinformation in a contentious and high-volume domain.

## Product Goal

- **Primary Goal:** Maximize the number of **accepted climate-related Community Notes** on X.com.
- **Secondary Goal:** Ensure the system is modular and reusable as an open-source framework for other domains and platforms.

## Users

- **Primary Users (PoC):** Project owner (you) and a small group of authenticated admins.
- **Public Users (PoC):** General public can view submitted and accepted notes via a minimal public website.

## Platforms & Scope

- **Platform Focus:** X.com’s Community Notes API.
- **Future Expansion:** Architecture should be modular enough to support future integration with other platforms (YouTube, TikTok, Facebook, Instagram, Threads).

## System Components (High-Level)

- **Ingestion Pipeline:** Pulls requested Community Notes from X.com.

  - Deduplication by platform and post_id (running the ingestion pipeline should not create duplicate entries)
  - Triggered by an external scheduler (GitHub Actions cron) or manually.

- **Classification:** Tags posts by topic (with MVP topic being climate)

  - Supports multi-topic classification (e.g., climate + politics).
  - Stores only the **latest classification result** (no history).
  - Admins can **rerun classification** with version tagging or manually override/add topics.

- **Note Generation:** Calls an external LangGraph-based fact-checking agent.

  - Generates **two outputs**: (1) a full-length fact check with no length limit, and (2) a concise community note capped at 280 characters.
  - Each 280-character note must include at least one link, pointing back to the hosted full fact check page.
  - Admins must be able to **regenerate notes** on demand.
  - Each draft linked to a **generator version** and prior drafts marked `superseded`.

- **Admin Review Workflow:**

  - Single-gate: AI draft → Admin edits/approves → Submit to X.

- **Submission:** Sends approved notes to X.com API with idempotency key support.
- **Reconciliation:** Check X for outcomes and updates DB.

  - Triggered by an external scheduler (GitHub Actions cron) or manually.

- **Database:**

  - Stores posts, topics, full fact checks, concise submitted notes, and outcomes.
  - Tracks classifier and generator versions.

- **Public Site:** Minimal interface listing submitted + accepted notes, with filtering by topic and status. Each published note links to its full-length fact check page.
- **Analytics Dashboard:** Displays accepted vs. submitted counts and optional time-to-note.

## Authentication & Access

- **Public:** Unauthenticated access to public site (read-only: submitted + accepted notes).
- **Admins:** Login via Google OAuth (or similar). Admins can review, edit, and submit notes.

## Failure Handling

- Failures stored in DB with `last_error` for posts.
- No silent skipping — classification or generation errors logged.
- Exponential backoff for retries.

## Tech Stack Requirements

- **Frontend:** React + Next.js (hosted on Vercel).
- **Backend:** FastAPI monolith (hosted on Fly.io).
- **Database:** Neon (PostgreSQL).
- **Scheduler:** External (GitHub Actions).
- **Fact-Checking Agent:** External LangGraph-based service.

# User Stories for AI Climate Community Note Writer

## Ingestion Pipeline

- **As a system**, I want to ingest Community Note requests from X.com so that I have a pool of candidate posts to evaluate.
- **As a system**, I want to deduplicate posts by platform and post_id so that no duplicates are created when re-running the pipeline.
- **As an admin**, I want to manually trigger the ingestion pipeline so that I can test or refresh data on demand.

## Classification

- **As a system**, I want to classify posts for climate relevance so that only relevant posts are passed to the AI note writer.
- **As an admin**, I want to rerun classification with the latest model so that improved classifiers can be applied retroactively.
- **As an admin**, I want to override or add topics manually so that misclassified posts can be corrected.

## Note Generation

- **As a system**, I want to generate a **full-length fact check** so that detailed explanations are available for public reference.
- **As a system**, I want to generate a **280-character community note** with at least one link back to the hosted full fact check so that it can be submitted within X’s limits.
- **As an admin**, I want to regenerate notes on demand so that I can get an updated draft if the first is unsatisfactory.
- **As a system**, I want to tag each draft with a generator version so that I can trace which version produced it.

## Admin Review Workflow

- **As an admin**, I want to edit AI-generated notes (both the full fact check and concise note) so that I can correct errors, improve clarity, or adjust tone before submission.
- **As an admin**, I want to approve and submit the concise note to X.com so that only vetted content is published.
- **As an admin**, I want to see which notes are superseded so that I can track the evolution of drafts.

## Submission & Reconciliation

- **As a system**, I want to submit the concise 280-character note (with link) to the X.com API with an idempotency key so that resubmissions don’t create duplicates.
- **As a system**, I want to poll X.com for submission outcomes so that I can reconcile which notes were accepted or rejected.

## Database

- **As a system**, I want to store posts, topics, full fact checks, concise notes, approved notes, and submission outcomes so that I have a complete record of the pipeline.
- **As a system**, I want to log classifier and generator versions so that I can track which models produced which outputs.
- **As a system**, I want to log failures with `last_error` so that admins can debug and retry.

## Public Site

- **As a public user**, I want to browse submitted and accepted notes so that I can see the system’s contributions.
- **As a public user**, I want to filter notes by topic and status so that I can find relevant notes.
- **As a public user**, I want to click on a concise note and view the full-length fact check so that I can see the detailed evidence.

## Analytics Dashboard

- **As a system owner**, I want to see the number of submitted notes so that I can track output.
- **As a system owner**, I want to see the number of accepted notes so that I can measure success.
- **As a system owner**, I want to see the median time from ingestion to submission (nice-to-have) so that I can monitor efficiency.

## Authentication & Access

- **As a public user**, I want to access the site without login so that I can freely view notes.
- **As an admin**, I want to log in with Google OAuth so that I can securely access the review and submission workflow.

# Acceptance Criteria

- End-to-end pipeline functional: ingest → classify → generate (full + concise) → admin review → submit → reconcile outcomes.
- Deduplication and idempotency working.
- Admins can regenerate notes with version tagging before submission.
- Admins can rerun classification with latest classifier version.
- Public site shows submitted and accepted notes with filters and links to full fact checks.
- Auth works with Google OAuth.
- Submitted and accepted counts tracked in analytics.
- Failures logged with appropriate status and errors.

# Out of Scope (PoC)

- Automated evaluator integration (X’s open-source evaluator).
- Reviewer load analytics.
- Advanced analytics (CTR, impressions, etc.).
- CI/CD, monitoring, observability.
